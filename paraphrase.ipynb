{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paraphrase.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIAbZWdJyJmX"
      },
      "source": [
        "# library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q48LjoumyTj1",
        "collapsed": true
      },
      "source": [
        "!pip install transformers==4.10.2\n",
        "!pip install sentencepiece==0.1.96\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print (\"device \",device)\n",
        "#model = model.to(device)\n",
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#https://github.com/shivamduseja/Deep-Summarization/blob/master/LSTM_with_attention.ipynb\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import unicodedata\n",
        "#Import utils and libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from typing import Callable, Optional\n",
        "from copy import deepcopy\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "#Import libraries for text procesing\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "\n",
        "#import pkbar\n",
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "import transformers as ppb \n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87MCeidFrSNp"
      },
      "source": [
        "# sentence paraphrase with pegasus\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/newmeqsum.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "fm63Cv8PpKBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d0HHNmlsn3h"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LACaIJTvJWO"
      },
      "source": [
        "#Installing dependencies\n",
        "!pip install sentence-splitter\n",
        "!pip install SentencePiece\n",
        "#importing the PEGASUS Transformer model\n",
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "model_name = 'tuner007/pegasus_paraphrase'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "#setting up the model\n",
        "def get_response(input_text,num_return_sequences):\n",
        "  batch = tokenizer.prepare_seq2seq_batch([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=70,num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl_Cjs5rO9rZ"
      },
      "source": [
        "# Takes the input paragraph and splits it into a list of sentences\n",
        "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
        "similar=[]\n",
        "splitter = SentenceSplitter(language='en')\n",
        "for j in range(800):\n",
        " sentence_list = splitter.split(x[j])\n",
        "#sentence_list\n",
        "# Do a for loop to iterate through the list of sentences and paraphrase each sentence in the iteration\n",
        " paraphrase = []\n",
        "\n",
        " for i in sentence_list:\n",
        "   a = get_response(i,1)\n",
        "   paraphrase.append(a)\n",
        "#creating the second split\n",
        " paraphrase2 = [' '.join(x) for x in paraphrase]\n",
        "# Combine the above splitted lists into a paragraph\n",
        " paraphrase3 = [' '.join(x for x in paraphrase2) ]\n",
        " paraphrased_text = str(paraphrase3).strip('[]').strip(\"'\")\n",
        "#paraphrased_text\n",
        " similar.append(paraphrased_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(similar) \n",
        "df.to_csv('testpara.csv')\n"
      ],
      "metadata": {
        "id": "R_EJHsoCATef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=pd.read_csv('testpara.csv')\n",
        "d"
      ],
      "metadata": {
        "id": "1DrzFVT2Btwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzZG6E0dPyBA"
      },
      "source": [
        "print(x[1])\n",
        "print(similar[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_3l7eXMwBdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J58TUy0PtIu"
      },
      "source": [
        "for j in range(len(x)):\n",
        "  x[j]=x[j]+\".\"+similar[j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKHJpRgAUYzD"
      },
      "source": [
        "df.to_csv('newpara.csv')\n",
        "from google.colab import files\n",
        "files.download(\"newpara.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8f6LVct5MAP"
      },
      "source": [
        ""
      ]
    }
  ]
}